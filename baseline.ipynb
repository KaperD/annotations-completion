{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "initial_feature_names = [\n",
    "    'targetName',\n",
    "    'className',\n",
    "    'returnType',\n",
    "    'methodModifiers',\n",
    "    'otherAnnotations',\n",
    "    'otherMethodsNames',\n",
    "    'otherMethodsAnnotations',\n",
    "    'returnsNull',\n",
    "    'checksNull',\n",
    "    'targetType'\n",
    "]\n",
    "class AnnotationUsage:\n",
    "    def __init__(self, usage_json):\n",
    "        self.annotation_name = usage_json['name']\n",
    "        features_json = usage_json['features']\n",
    "        self.features_list = [\n",
    "            features_json.get('targetName', ''),\n",
    "            features_json.get('className', ''),\n",
    "            features_json.get('returnType', ''),\n",
    "            features_json.get('methodModifiers', []),\n",
    "            features_json.get('otherAnnotations', []),\n",
    "            features_json.get('otherMethodsNames', []),\n",
    "            features_json.get('otherMethodsAnnotations', []),\n",
    "            1 if features_json.get('returnsNull', False) else 0,\n",
    "            1 if features_json.get('checksNull', False) else 0,\n",
    "        ]\n",
    "        self.file_path = usage_json['filePath']\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.annotation_name}'\n",
    "\n",
    "class UsagesLoader:\n",
    "    def __init__(self, processing_result_path):\n",
    "        self.processing_result_path = processing_result_path\n",
    "\n",
    "    def load(self):\n",
    "        usages_by_target = defaultdict(list)\n",
    "        for root, dirs, files in os.walk(self.processing_result_path):\n",
    "            for file in files:\n",
    "                if not file.endswith('json'):\n",
    "                    continue\n",
    "                with open(os.path.join(root, file), 'r') as read_file:\n",
    "                    data = json.load(read_file)\n",
    "                    target_type = data['keyInfo']['name']\n",
    "                    new_usages = [AnnotationUsage(usage_json) for usage_json in data[\"usages\"]]\n",
    "                    for usage in new_usages:\n",
    "                        usage.features_list.append(target_type)\n",
    "                    usages_by_target[target_type] = usages_by_target[target_type] + new_usages\n",
    "        return usages_by_target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Baseline:\n",
    "    def __init__(self):\n",
    "        self.ordered_by_quantity = np.array([])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.ordered_by_quantity = np.array([x[0] for x in Counter(y).most_common()])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.ordered_by_quantity for _ in X])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self, predicted_y, expected_y):\n",
    "        self.orders = [(list(predicted_y[i]) + [expected_y[i]]).index(expected_y[i]) + 1 for i in range(len(expected_y))]\n",
    "        # for i in range(len(expected_y)):\n",
    "        #     if expected_y[i] != predicted_y[i][0]:\n",
    "        #         print(expected_y[i], predicted_y[i][0])\n",
    "\n",
    "    def top_i(self, i):\n",
    "        return sum(map(lambda x: x <= i, self.orders)) / len(self.orders)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def encode_names(column, train_size, column_name, max_new_columns):\n",
    "    \"\"\"\n",
    "    Converts column of camelCase names to 100 columns with most popular words\n",
    "    with 1 (if name contains word) and 0 (otherwise)\n",
    "    \"\"\"\n",
    "\n",
    "    def split_camel_case(x):\n",
    "        words = [word.lower() for word in re.findall(r'[A-Z]?[a-z]+|[A-Z]+(?=[A-Z]|$)', x)]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    vectorizer = CountVectorizer(preprocessor=split_camel_case, max_features=max_new_columns)\n",
    "    vectorizer.fit(column[:train_size])\n",
    "    new_columns = vectorizer.transform(column).toarray()\n",
    "    new_names = [column_name + '_' + name for name in vectorizer.get_feature_names_out()]\n",
    "    return new_columns, new_names\n",
    "\n",
    "def encode_lists(column, train_size, column_name, max_new_columns):\n",
    "    \"\"\"\n",
    "    Converts column of lists of words to 100 columns with most popular words\n",
    "    with 1 (if list contains word) and 0 (otherwise)\n",
    "    \"\"\"\n",
    "\n",
    "    joined_words = np.array([' '.join(x).replace('.', '') for x in column])\n",
    "\n",
    "    vectorizer = CountVectorizer(max_features=max_new_columns)\n",
    "    vectorizer.fit(joined_words[:train_size])\n",
    "    new_columns = vectorizer.transform(joined_words).toarray()\n",
    "    new_names = [column_name + '_' + name for name in vectorizer.get_feature_names_out()]\n",
    "    return new_columns, new_names\n",
    "\n",
    "\n",
    "def encode_column(column, train_size, column_name, max_new_columns):\n",
    "    \"\"\"\n",
    "    Converts column of some type to column of integers\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(column[0], str):\n",
    "        if (column[:train_size] == '').all():\n",
    "            return None, []\n",
    "        return encode_names(column, train_size, column_name, max_new_columns)\n",
    "    elif isinstance(column[0], list):\n",
    "        if np.alltrue([x == [] for x in column[:train_size]]):\n",
    "            return None, []\n",
    "        return encode_lists(column, train_size, column_name, max_new_columns)\n",
    "    else:\n",
    "        return np.array([column.astype(np.int64)]).T, [column_name]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[1, 1, 1],\n        [0, 0, 1]]),\n ['a_get', 'a_good', 'a_something'])"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_column(np.array(['getSomethingGood', 'returnSomething'], dtype=object), 1, 'a', 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[1],\n        [1]]),\n ['b_public'])"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_column(np.array([['public'], ['public', 'static']], dtype=object), 1, 'b', 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[1],\n        [0]]),\n ['c'])"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_column(np.array([1, 0], dtype=object), 1, 'c', 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "usages_loader = UsagesLoader(\n",
    "    '/Users/danilbk/Programming/Kotlin/test/intellij-community/project-processing-results/processing/java/annotations/processing/0.0.0')\n",
    "usages_by_target_type = usages_loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def load_for_target(target_type, max_new_columns = 100, size = 10000, train_size = 0.8, state = 42, ignored_annotation=()):\n",
    "    method_usages = list(\n",
    "        filter(lambda x: x.annotation_name not in ignored_annotation, usages_by_target_type[target_type]))\n",
    "    method_usages = shuffle(method_usages, random_state=state)[:size]\n",
    "    raw_X = np.array([np.array(usage.features_list, dtype=object) for usage in method_usages])\n",
    "    X = None\n",
    "    all_new_names = []\n",
    "    if len(raw_X) == 0:\n",
    "        X = np.array([])\n",
    "        all_new_names = initial_feature_names\n",
    "    else:\n",
    "        for col in range(raw_X.shape[1]):\n",
    "            new_columns, new_names = encode_column(raw_X[:, col], round(len(raw_X[:, col]) * train_size), initial_feature_names[col], max_new_columns)\n",
    "            if new_columns is None:\n",
    "                continue\n",
    "            all_new_names += new_names\n",
    "            if X is None:\n",
    "                X = new_columns\n",
    "            else:\n",
    "                X = np.concatenate((X, new_columns), axis=1)\n",
    "    y = np.array([usage.annotation_name for usage in method_usages])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, shuffle=False)\n",
    "    return X_train, X_test, y_train, y_test, all_new_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def calculate(X_train, X_test, y_train, y_test, model):\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "\n",
    "    metric = Metric(predicted, y_test)\n",
    "    # print(f'Count: {len(y_test)}')\n",
    "    for i in range(1, 2):\n",
    "        print(f'Top {i}: {metric.top_i(i)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "target_types = [\n",
    "    'AnnotationType',\n",
    "    'Constructor',\n",
    "    'Field',\n",
    "    'LocalVariable',\n",
    "    'Method',\n",
    "    'Module',\n",
    "    'Package',\n",
    "    'Parameter',\n",
    "    'RecordComponent',\n",
    "    'Type',\n",
    "    'TypeParameter',\n",
    "    'TypeUse'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class WrapperModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.flip(self.model.classes_[np.argsort(proba)]) for proba in self.model.predict_proba(X)])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, c=1, need_scaler=False):\n",
    "        self.svm = SVC(C=c, probability=True)\n",
    "        self.model = self.svm\n",
    "        if need_scaler:\n",
    "            self.model = make_pipeline(StandardScaler(), self.model)\n",
    "        # self.model = SVC(kernel=kernel, probability=True, degree=degree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.flip(self.model.classes_[np.argsort(proba)]) for proba in self.model.predict_proba(X)])\n",
    "        # return np.array([np.array([y_pred]) for y_pred in self.model.predict(X)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "class LinearSVM:\n",
    "    def __init__(self, c=1, need_scaler=False):\n",
    "        self.model = LinearSVC(C=c, max_iter=1000)\n",
    "        if need_scaler:\n",
    "            self.model = make_pipeline(StandardScaler(), self.model)\n",
    "        self.model = CalibratedClassifierCV(self.model)\n",
    "        # self.model = OneVsRestClassifier(self.model)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.flip(self.model.classes_[np.argsort(proba)]) for proba in self.model.predict_proba(X)])\n",
    "        # return np.array([np.array([y_pred]) for y_pred in self.model.predict(X)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class LogisticReg:\n",
    "    def __init__(self, C=1, solver='lbfgs', need_scaler=False):\n",
    "        self.model = LogisticRegression(max_iter=1000, C=C, solver=solver)\n",
    "        if need_scaler:\n",
    "            self.model = make_pipeline(StandardScaler(), self.model)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.flip(self.model.classes_[np.argsort(proba)]) for proba in self.model.predict_proba(X)])\n",
    "        # return np.array([np.array([y_pred]) for y_pred in self.model.predict(X)])\n",
    "    def score(self, X, y=None, sample_weight=None):\n",
    "        self.model.score(X, y=y, sample_weight=sample_weight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestClassifier(n_estimators=100, n_jobs=8)\n",
    "        # self.model = SVC(kernel=kernel, probability=True, degree=degree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.flip(self.model.classes_[np.argsort(proba)]) for proba in self.model.predict_proba(X)])\n",
    "        # return np.array([np.array([y_pred]) for y_pred in self.model.predict(X)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(self):\n",
    "        self.model = GradientBoostingClassifier()\n",
    "        # self.model = SVC(kernel=kernel, probability=True, degree=degree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.flip(self.model.classes_[np.argsort(proba)]) for proba in self.model.predict_proba(X)])\n",
    "        # return np.array([np.array([y_pred]) for y_pred in self.model.predict(X)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self):\n",
    "        base_estim = DecisionTreeClassifier(max_depth=1, max_features='sqrt')\n",
    "        self.model = AdaBoostClassifier(base_estimator=base_estim, n_estimators=500, learning_rate=0.5)\n",
    "        # self.model = SVC(kernel=kernel, probability=True, degree=degree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.flip(self.model.classes_[np.argsort(proba)]) for proba in self.model.predict_proba(X)])\n",
    "        # return np.array([np.array([y_pred]) for y_pred in self.model.predict(X)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "class CatBoost:\n",
    "    def __init__(self):\n",
    "        self.model = CatBoostClassifier(\n",
    "                                        verbose=False,\n",
    "                                        thread_count=8)\n",
    "        # self.model = SVC(kernel=kernel, probability=True, degree=degree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.flip(self.model.classes_[np.argsort(proba)]) for proba in self.model.predict_proba(X)])\n",
    "        # return np.array([np.array([y_pred]) for y_pred in self.model.predict(X)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "class Ridge:\n",
    "    def __init__(self, c=1, need_scaler=False):\n",
    "        if need_scaler:\n",
    "            self.model = make_pipeline(StandardScaler(), RidgeClassifierCV())\n",
    "        else:\n",
    "            self.model = RidgeClassifierCV()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.flip(self.model.classes_[np.argsort(proba)]) for proba in self.model.predict_proba(X)])\n",
    "        # return np.array([np.array([y_pred]) for y_pred in self.model.predict(X)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self):\n",
    "        self.model = MLPClassifier(verbose=False, hidden_layer_sizes=(10, 10, 10))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([np.flip(self.model.classes_[np.argsort(proba)]) for proba in self.model.predict_proba(X)])\n",
    "        # return np.array([np.array([y_pred]) for y_pred in self.model.predict(X)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for degree in [3, 4, 5, 10, 20, 100]:\n",
    "    for target_type in ['Method']:\n",
    "        X, y, feature_names = load_for_target(target_type)\n",
    "        rnd = random.Random(42)\n",
    "        for _ in range(1):\n",
    "            size = 10000\n",
    "            X, y = shuffle(X, y)\n",
    "            X = X[:size]\n",
    "            y = y[:size]\n",
    "            if len(X) == 0:\n",
    "                continue\n",
    "            print(degree)\n",
    "            svm = SVM()\n",
    "            print(\"SVM\")\n",
    "            calculate(X, y, svm)\n",
    "            print(\"Logistic regression\")\n",
    "            calculate(X, y, LogisticReg())\n",
    "            print(\"Baseline\")\n",
    "            calculate(X, y, Baseline())\n",
    "            print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method\n",
      "Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.874\n",
      "CatBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for target_type in ['Method']:\n",
    "    X_train, X_test, y_train, y_test, feature_names = load_for_target(target_type, 100, size=10000, train_size=0.8)\n",
    "    for _ in range(1):\n",
    "        if len(X) == 0:\n",
    "            continue\n",
    "        print(target_type)\n",
    "        print(\"Linear SVM\")\n",
    "        calculate(X_train, X_test, y_train, y_test, LinearSVM())\n",
    "        print(\"CatBoost\")\n",
    "        calculate(X_train, X_test, y_train, y_test, CatBoost())\n",
    "        print(\"Logistic regression\")\n",
    "        calculate(X_train, X_test, y_train, y_test, LogisticReg())\n",
    "        # model = GridSearchCV(estimator=LogisticRegression(),\n",
    "        #                      param_grid={'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'C': [0.01, 0.1, 0.2, 1, 2, 10]})\n",
    "        # calculate(X, y, WrapperModel(model))\n",
    "        print(\"Baseline\")\n",
    "        calculate(X_train, X_test, y_train, y_test, Baseline())\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotationType\n",
      "CatBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.8977635782747604\n",
      "Gradient Boosting\n",
      "Top 1: 0.8498402555910544\n",
      "Random Forest\n",
      "Top 1: 0.8785942492012779\n",
      "SVM\n",
      "Top 1: 0.8210862619808307\n",
      "Linear SVM\n",
      "Top 1: 0.8785942492012779\n",
      "Logistic regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.8594249201277955\n",
      "Baseline\n",
      "Top 1: 0.38338658146964855\n",
      "\n",
      "Constructor\n",
      "CatBoost\n",
      "Top 1: 0.5237226277372263\n",
      "Gradient Boosting\n",
      "Top 1: 0.44525547445255476\n",
      "Random Forest\n",
      "Top 1: 0.4981751824817518\n",
      "SVM\n",
      "Top 1: 0.4197080291970803\n",
      "Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.4854014598540146\n",
      "Logistic regression\n",
      "Top 1: 0.5237226277372263\n",
      "Baseline\n",
      "Top 1: 0.31386861313868614\n",
      "\n",
      "Field\n",
      "CatBoost\n",
      "Top 1: 0.71975\n",
      "Gradient Boosting\n",
      "Top 1: 0.705125\n",
      "Random Forest\n",
      "Top 1: 0.717125\n",
      "SVM\n",
      "Top 1: 0.661375\n",
      "Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.679625\n",
      "Logistic regression\n",
      "Top 1: 0.694875\n",
      "Baseline\n",
      "Top 1: 0.551625\n",
      "\n",
      "LocalVariable\n",
      "CatBoost\n",
      "Top 1: 0.7039911308203991\n",
      "Gradient Boosting\n",
      "Top 1: 0.6917960088691796\n",
      "Random Forest\n",
      "Top 1: 0.7023281596452328\n",
      "SVM\n",
      "Top 1: 0.5886917960088692\n",
      "Linear SVM\n",
      "Top 1: 0.7056541019955654\n",
      "Logistic regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.6990022172949002\n",
      "Baseline\n",
      "Top 1: 0.37971175166297116\n",
      "\n",
      "Method\n",
      "CatBoost\n",
      "Top 1: 0.8565\n",
      "Gradient Boosting\n",
      "Top 1: 0.837875\n",
      "Random Forest\n",
      "Top 1: 0.848375\n",
      "SVM\n",
      "Top 1: 0.7135\n",
      "Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.8315\n",
      "Logistic regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.84125\n",
      "Baseline\n",
      "Top 1: 0.512\n",
      "\n",
      "Package\n",
      "CatBoost\n",
      "Top 1: 0.65625\n",
      "Gradient Boosting\n",
      "Top 1: 0.65625\n",
      "Random Forest\n",
      "Top 1: 0.65625\n",
      "SVM\n",
      "Top 1: 0.640625\n",
      "Linear SVM\n",
      "Top 1: 0.640625\n",
      "Logistic regression\n",
      "Top 1: 0.640625\n",
      "Baseline\n",
      "Top 1: 0.28125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter\n",
      "CatBoost\n",
      "Top 1: 0.8455\n",
      "Gradient Boosting\n",
      "Top 1: 0.830625\n",
      "Random Forest\n",
      "Top 1: 0.84475\n",
      "SVM\n",
      "Top 1: 0.84275\n",
      "Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.837375\n",
      "Logistic regression\n",
      "Top 1: 0.82675\n",
      "Baseline\n",
      "Top 1: 0.836375\n",
      "\n",
      "Type\n",
      "CatBoost\n",
      "Top 1: 0.8151983860121049\n",
      "Gradient Boosting\n",
      "Top 1: 0.8111634162743779\n",
      "Random Forest\n",
      "Top 1: 0.8045729657027573\n",
      "SVM\n",
      "Top 1: 0.7339609952925353\n",
      "Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.808338937457969\n",
      "Logistic regression\n",
      "Top 1: 0.8090114324142569\n",
      "Baseline\n",
      "Top 1: 0.34001344989912574\n",
      "\n",
      "TypeUse\n",
      "CatBoost\n",
      "Top 1: 0.887625\n",
      "Gradient Boosting\n",
      "Top 1: 0.876375\n",
      "Random Forest\n",
      "Top 1: 0.88525\n",
      "SVM\n",
      "Top 1: 0.87325\n",
      "Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nir/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: 0.869125\n",
      "Logistic regression\n",
      "Top 1: 0.877625\n",
      "Baseline\n",
      "Top 1: 0.85475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for target_type in target_types:\n",
    "    for _ in range(1):\n",
    "        X, y, feature_names = load_for_target(target_type)\n",
    "        size = 10000\n",
    "        X, y = shuffle(X, y)\n",
    "        X = X[:size]\n",
    "        y = y[:size]\n",
    "        if len(X) == 0:\n",
    "            continue\n",
    "        print(target_type)\n",
    "        print(\"CatBoost\")\n",
    "        calculate(X, y, CatBoost())\n",
    "        print(\"Gradient Boosting\")\n",
    "        calculate(X, y, GradientBoosting())\n",
    "        print(\"Random Forest\")\n",
    "        calculate(X, y, RandomForest())\n",
    "        print(\"SVM\")\n",
    "        calculate(X, y, SVM())\n",
    "        print(\"Linear SVM\")\n",
    "        calculate(X, y, LinearSVM())\n",
    "        print(\"Logistic regression\")\n",
    "        calculate(X, y, LogisticReg())\n",
    "        print(\"Baseline\")\n",
    "        calculate(X, y, Baseline())\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "all_usages = []\n",
    "for target_type in target_types:\n",
    "    all_usages += list(filter(lambda x: x.annotation_name not in ['java.lang.Override'], usages_by_target_type[target_type]))\n",
    "\n",
    "test_usages = []\n",
    "train_usages = []\n",
    "for usage in all_usages:\n",
    "    if usage.file_path.startswith('java/idea-ui'):\n",
    "        test_usages.append(usage)\n",
    "    else:\n",
    "        train_usages.append(usage)\n",
    "train_usages = shuffle(train_usages)\n",
    "\n",
    "size = 100000\n",
    "\n",
    "all_usages = train_usages[:size] + test_usages\n",
    "\n",
    "raw_X = np.array([np.array(usage.features_list, dtype=object) for usage in all_usages])\n",
    "X = None\n",
    "all_new_names = []\n",
    "if len(raw_X) == 0:\n",
    "    X = np.array([])\n",
    "    all_new_names = initial_feature_names\n",
    "else:\n",
    "    for col in range(raw_X.shape[1]):\n",
    "        new_columns, new_names = encode_column(raw_X[:, col], size, initial_feature_names[col], 100)\n",
    "        if new_columns is None:\n",
    "            continue\n",
    "        all_new_names += new_names\n",
    "        if X is None:\n",
    "            X = new_columns\n",
    "        else:\n",
    "            X = np.concatenate((X, new_columns), axis=1)\n",
    "y = [usage.annotation_name for usage in all_usages]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i in range(len(X)):\n",
    "    if all_usages[i].file_path.startswith('java/idea-ui'):\n",
    "        X_test.append(X[i])\n",
    "        y_test.append(y[i])\n",
    "    else:\n",
    "        X_train.append(X[i])\n",
    "        y_train.append(y[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "3046"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "100000"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# X_train, y_train = shuffle(X_train, y_train)\n",
    "# X_train = X_train[:1000]\n",
    "# y_train = y_train[:1000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "def calc(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "\n",
    "    metric = Metric(predicted, y_test)\n",
    "    # print(f'Count: {len(y_test)}')\n",
    "    for i in range(1, 6):\n",
    "        print(f'Top {i}: {metric.top_i(i)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest\n",
      "Top 1: 0.7774130006565988\n",
      "Top 2: 0.9652002626395273\n",
      "Top 3: 0.9799737360472751\n",
      "Top 4: 0.9852265265922522\n",
      "Top 5: 0.9885095206828628\n",
      "Baseline\n",
      "Top 1: 0.6966513460275772\n",
      "Top 2: 0.9182534471437951\n",
      "Top 3: 0.9182534471437951\n",
      "Top 4: 0.9425476034143139\n",
      "Top 5: 0.9445173998686802\n"
     ]
    }
   ],
   "source": [
    "# print('Linear SVM')\n",
    "# calc(LinearSVM(c=0.2))\n",
    "# print('Ridge')\n",
    "# calc(Ridge())\n",
    "# print('Ð¡atBoost')\n",
    "# calc(CatBoost())\n",
    "print('Forest')\n",
    "calc(RandomForest())\n",
    "# print(\"Logistic regression\")\n",
    "# calc(LogisticReg(c=0.2))\n",
    "# print('SVM')\n",
    "# calc(SVM(c=0.2))\n",
    "print('Baseline')\n",
    "calc(Baseline())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def load_for_target2(target_type, ignored_feature, ignored_annotation=()):\n",
    "    method_usages = list(\n",
    "        filter(lambda x: x.annotation_name not in ignored_annotation, usages_by_target_type[target_type]))\n",
    "    raw_X = np.array([np.array(usage.features_list, dtype=object) for usage in method_usages])\n",
    "    X = None\n",
    "    all_new_names = []\n",
    "    if len(raw_X) == 0:\n",
    "        X = np.array([])\n",
    "        all_new_names = initial_feature_names\n",
    "    else:\n",
    "        for col in range(raw_X.shape[1]):\n",
    "            if col == ignored_feature:\n",
    "                continue\n",
    "            new_columns, new_names = encode_column(raw_X[:, col], initial_feature_names[col])\n",
    "            if new_columns is None:\n",
    "                continue\n",
    "            all_new_names += new_names\n",
    "            if X is None:\n",
    "                X = new_columns\n",
    "            else:\n",
    "                X = np.concatenate((X, new_columns), axis=1)\n",
    "    y = np.array([usage.annotation_name for usage in method_usages])\n",
    "    return X, y, all_new_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "SVM\n",
      "Top 1: 0.834\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "1\n",
      "SVM\n",
      "Top 1: 0.842625\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "2\n",
      "SVM\n",
      "Top 1: 0.819625\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "3\n",
      "SVM\n",
      "Top 1: 0.81025\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "4\n",
      "SVM\n",
      "Top 1: 0.724125\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "5\n",
      "SVM\n",
      "Top 1: 0.84425\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "6\n",
      "SVM\n",
      "Top 1: 0.82475\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "7\n",
      "SVM\n",
      "Top 1: 0.82775\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "8\n",
      "SVM\n",
      "Top 1: 0.839625\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "9\n",
      "SVM\n",
      "Top 1: 0.839625\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(initial_feature_names)):\n",
    "    X, y, feature_names = load_for_target2('Method', i)\n",
    "    rnd = random.Random(42)\n",
    "    for _ in range(1):\n",
    "        size = 10000\n",
    "        X, y = shuffle(X, y, random_state=42)\n",
    "        X = X[:size]\n",
    "        y = y[:size]\n",
    "        if len(X) == 0:\n",
    "            continue\n",
    "        svm = SVM()\n",
    "        print(initial_feature_names[i])\n",
    "        print(\"SVM\")\n",
    "        calculate(X, y, svm)\n",
    "        print(\"Baseline\")\n",
    "        calculate(X, y, Baseline())\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def load_for_target3(target_type, used_feature, ignored_annotation=()):\n",
    "    method_usages = list(\n",
    "        filter(lambda x: x.annotation_name not in ignored_annotation, usages_by_target_type[target_type]))\n",
    "    raw_X = np.array([np.array(usage.features_list, dtype=object) for usage in method_usages])\n",
    "    X = None\n",
    "    all_new_names = []\n",
    "    if len(raw_X) == 0:\n",
    "        X = np.array([])\n",
    "        all_new_names = initial_feature_names\n",
    "    else:\n",
    "        for col in range(raw_X.shape[1]):\n",
    "            if col != used_feature:\n",
    "                continue\n",
    "            new_columns, new_names = encode_column(raw_X[:, col], initial_feature_names[col])\n",
    "            if new_columns is None:\n",
    "                continue\n",
    "            all_new_names += new_names\n",
    "            if X is None:\n",
    "                X = new_columns\n",
    "            else:\n",
    "                X = np.concatenate((X, new_columns), axis=1)\n",
    "    y = np.array([usage.annotation_name for usage in method_usages])\n",
    "    return X, y, all_new_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "SVM\n",
      "Top 1: 0.611125\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "1\n",
      "SVM\n",
      "Top 1: 0.5655\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "2\n",
      "SVM\n",
      "Top 1: 0.525\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "3\n",
      "SVM\n",
      "Top 1: 0.581875\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "4\n",
      "SVM\n",
      "Top 1: 0.60675\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "5\n",
      "SVM\n",
      "Top 1: 0.60975\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "6\n",
      "SVM\n",
      "Top 1: 0.655\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "7\n",
      "SVM\n",
      "Top 1: 0.514125\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "8\n",
      "SVM\n",
      "Top 1: 0.505125\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n",
      "9\n",
      "SVM\n",
      "Top 1: 0.505125\n",
      "Baseline\n",
      "Top 1: 0.505125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(initial_feature_names)):\n",
    "    X, y, feature_names = load_for_target3('Method', i)\n",
    "    rnd = random.Random(42)\n",
    "    for _ in range(1):\n",
    "        size = 10000\n",
    "        X, y = shuffle(X, y, random_state=42)\n",
    "        X = X[:size]\n",
    "        y = y[:size]\n",
    "        if len(X) == 0:\n",
    "            continue\n",
    "        svm = SVM()\n",
    "        print(initial_feature_names[i])\n",
    "        print(\"SVM\")\n",
    "        calculate(X, y, svm)\n",
    "        print(\"Baseline\")\n",
    "        calculate(X, y, Baseline())\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}